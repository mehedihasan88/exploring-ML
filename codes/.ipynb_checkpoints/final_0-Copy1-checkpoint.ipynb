{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code implementation of - **A. Alahmadi, M. Hussain, H. Aboalsamh, G. Muhammad, G. Bebis, and H. Mathkour, “Passive detection of image forgery using dct and local binary pattern,” Signal, Image and Video Processing, vol. 11, no. 1, pp. 81–88, Jan 2017. [Online]. Available: https://doi.org/10.1007/s11760-016-0899-0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from scipy.fftpack import dct\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block-size (non-overlapping)\n",
    "split_width = 16\n",
    "split_height = 16\n",
    "\n",
    "# LBP parameters\n",
    "P = 8\n",
    "R = 1.0\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function devides an image into blocks\n",
    "# parameters\n",
    "#     parameter(1) : size of the image\n",
    "#     parameter(2) : splitting size\n",
    "#     parameter(3) : amount of overlapping (by default 0)\n",
    "# return type  : return a list of starting points of the blocks\n",
    "\n",
    "def start_points(size, split_size, overlap=0):\n",
    "    points = [0]\n",
    "    stride = int(split_size * (1-overlap))\n",
    "    counter = 1\n",
    "    while True:\n",
    "        pt = stride * counter\n",
    "        if pt + split_size >= size:\n",
    "            points.append(size - split_size)\n",
    "            break\n",
    "        else:\n",
    "            points.append(pt)\n",
    "        counter += 1\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts features from all the images in a folder\n",
    "# parameters : \n",
    "#     parameter(1) : path to the folder\n",
    "#     parameter(2) : class label of the images in that folder(forged or not)\n",
    "# return types : stores the features in the list \n",
    "\n",
    "def feature_extraction(path_to_folder, class_label):\n",
    "    for file_name in os.listdir(path_to_folder):\n",
    "        \n",
    "        # join image file name with the path to the folder\n",
    "        # to get full path of the image file\n",
    "        path_to_img = os.path.join(path_to_folder,file_name)\n",
    "        img = cv2.imread(path_to_img)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if the image file is empty or didn't load continue from beginining\n",
    "        if np.shape(img) == ():\n",
    "            continue\n",
    "            \n",
    "        # converts the image into YCrCb color space and take the Cr component only\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb) \n",
    "        img = img[:,:,1]\n",
    "        img_h, img_w = img.shape\n",
    "        \n",
    "        \n",
    "        # calculates the starting points of the blocks\n",
    "        X_points = start_points(img_w, split_width, 0.0)\n",
    "        Y_points = start_points(img_h, split_height, 0.0)\n",
    "        \n",
    "        \n",
    "        # calculates dct for eact block of an image\n",
    "        dct_blocks=[]\n",
    "        for i in Y_points:\n",
    "            for j in X_points:\n",
    "                block = img[i:i+split_height, j:j+split_width] # contains the non-overlapping block \n",
    "                lbp = local_binary_pattern(block, P, R, method='default')\n",
    "                dct_block = dct(lbp, type=2, n=None, axis=-1, norm=None, overwrite_x=False)\n",
    "                dct_blocks.append(dct_block)\n",
    "        \n",
    "        dct_blocks_array=np.asarray(dct_blocks)\n",
    "        \n",
    "        _,r,c=dct_blocks_array.shape\n",
    "        \n",
    "        \n",
    "        img_std_list=[] #length should be r*c i.e 16*16=256 in our case.\n",
    "        with_name_list=[file_name,class_label]\n",
    "        \n",
    "        for x in range(r):\n",
    "            for y in range(c):\n",
    "                pixel_depth_subarr=dct_blocks_array[:,x,y]\n",
    "                std=np.std(pixel_depth_subarr)\n",
    "                img_std_list.append(std)\n",
    "                with_name_list.append(std)\n",
    "        \n",
    "        #name_list.append(file_name) \n",
    "        feature_vector.append(img_std_list)\n",
    "        label.append(class_label)\n",
    "        dataframe_list.append(with_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_vector=[]\n",
    "label=[]\n",
    "# name_list=[]\n",
    "dataframe_list=[]\n",
    "\n",
    "# #CASIA V1.0 dataset\n",
    "au_path = \"E:\\FinalProject\\learning\\dataset\\working\\CASIA1\\Au\\Au\" \n",
    "tp_path1 = \"E:\\FinalProject\\learning\\dataset\\working\\CASIA1\\Modified Tp\\Tp\\CM\"\n",
    "tp_path2 = \"E:\\FinalProject\\learning\\dataset\\working\\CASIA1\\Modified Tp\\Tp\\Sp\"\n",
    "feature_extraction(au_path, 0)\n",
    "feature_extraction(tp_path1, 1)\n",
    "feature_extraction(tp_path2, 1)\n",
    "# Columbia dataset\n",
    "# au_path=\"YOUR_PATH/Columbia_ImSpliceDataset/authentic\"\n",
    "# tp_path=\"YOUR_PATH/Columbia_ImSpliceDataset/spliced\"\n",
    "# feature_extraction(au_path, 0)\n",
    "# feature_extraction(tp_path, 1)\n",
    "\n",
    "# CASIA V2.0 Dataset\n",
    "# au_path=\"YOUR_PATH/CASIA2.0_revised/Au\"\n",
    "# tp_path=\"YOUR_PATH/CASIA2.0_revised/Tp\"\n",
    "# feature_extraction(au_path, 0)\n",
    "# feature_extraction(tp_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length/Dimension of features\", len(feature_vector[0]))\n",
    "print(\"Length of feature vector\", len(feature_vector))\n",
    "print(\"length of label\",len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dataframe_list)\n",
    "df.rename(columns = {0: \"image_names\"}, inplace = True)\n",
    "# df['label']=label #To add label column as well\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_norm = MinMaxScaler() \n",
    "df.iloc[:,1:] = scaler_norm.fit_transform(df.iloc[:,1:].to_numpy()) # Normalising the values in dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_csv=\"CASIA2_feature.csv\"\n",
    "path_csv=\"CASIA1_feature.csv\"\n",
    "# path_csv=\"Columbia_feature.csv\"\n",
    "\n",
    "df.to_csv(path_csv) #saving dataframe to csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('YOUR_PATH/___features.csv')\n",
    "df=pd.read_csv(\"CASIA1_feature.csv\")\n",
    "array=df.values\n",
    "x_feature=array[:,3:]\n",
    "y_label=array[:,2].astype('int')\n",
    "print(x_feature.shape)\n",
    "print(y_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(x_feature,y_label,test_size=0.10,random_state=7)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SVC=SVC(C=32,kernel='rbf',gamma=0.03125)\n",
    "\n",
    "# Random check\n",
    "kfold=KFold(n_splits=10)\n",
    "cv_results=cross_val_score(model_SVC,X_train,Y_train,cv=kfold,scoring='accuracy')\n",
    "msg=\"%s %f (%f)\" % ('Training Accuracy: ',cv_results.mean(),cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SVC = SVC(C=32,gamma=0.03125, kernel='rbf') #Can also try for GridSearch yourself\n",
    "model_SVC.fit(X_train,Y_train) \n",
    "\n",
    "predictions=model_SVC.predict(X_test)\n",
    "\n",
    "# displaying confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(Y_test, predictions)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
